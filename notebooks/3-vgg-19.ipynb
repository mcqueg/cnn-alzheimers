{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. VGG-19\n",
    "\n",
    "#### Garrett McCue\n",
    "\n",
    "The first model architecture we will explore for classifying the images is the [VGG19](https://arxiv.org/abs/1409.1556) architecture. The model architecture and pretrained weights from the ImageNet dataset can easily be downloaded and compiled from [Tensorflow and Keras](https://www.tensorflow.org/api_docs/python/tf/keras/applications/vgg19) for transfer learning applications.\n",
    "\n",
    "The process of transfer learning for ConvNets includes:\n",
    "\n",
    "1. Getting only the convolutional layers and associated pretrained weights of the model.\n",
    "2. Freeze the weights of the pretrained convolutional layers\n",
    "3. Attach Dense connected layers to the top\n",
    "4. Train Dense top layers on the desired task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/garrettmccue/projects/cnn-alzheimers'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# set correct local working directory and useful paths\n",
    "ROOT = '/Users/garrettmccue/projects/cnn-alzheimers'\n",
    "data_path = f'{ROOT}/data'\n",
    "weights_path = f'{ROOT}/models/raw'\n",
    "\n",
    "os.chdir(ROOT)\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the pre-trained weights. No top means it excludes the fully connected layer it uses for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-07-18 17:29:47--  https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.0.176, 172.217.2.48, 142.250.191.240, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.0.176|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 80134624 (76M) [application/octet-stream]\n",
      "Saving to: ‘/Users/garrettmccue/projects/cnn-alzheimers/models/raw/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
      "\n",
      "/Users/garrettmccue 100%[===================>]  76.42M  43.8MB/s    in 1.7s    \n",
      "\n",
      "2022-07-18 17:29:49 (43.8 MB/s) - ‘/Users/garrettmccue/projects/cnn-alzheimers/models/raw/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [80134624/80134624]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
    "    -O /Users/garrettmccue/projects/cnn-alzheimers/models/raw/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-18 17:31:47.303327: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 256, 256, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 256, 256, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 128, 128, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 128, 128, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 128, 128, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 64, 64, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 64, 64, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 32, 32, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 16, 16, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 0\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# set the downloaded weights file to a variable\n",
    "local_weights_path = f'{weights_path}/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "# Initialize base model from tensorflow.keras\n",
    "# Set the input shape and remove dense layers (top), to match our weights file\n",
    "# our image shapes are (256x256)\n",
    "pre_trained_model = VGG19(input_shape = (256, 256, 3),\n",
    "                                include_top= False,\n",
    "                                weights = None)\n",
    "\n",
    "# load pretrained weights\n",
    "pre_trained_model.load_weights(local_weights_path)\n",
    "\n",
    "# freeze weights of each layer\n",
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "pre_trained_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the head has been removed and this network isnt as deep as the inception-v3 model we will take the output from the last layer and feed it into an attached dense network. Since we are going to be adding dense networks to more models we can create a utilities function to handle this and use it to add the dense layers to the vgg19 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate the output of the `block5_pool` layer so it can be fed into the dense network.\n",
    "LAST_LAYER = 'block5_pool'\n",
    "print(f'Setting last layer as: {LAST_LAYER}')\n",
    "last_layer = pre_trained_model.get_layer(LAST_LAYER)\n",
    "print(f'Last layer output shape: {last_layer.output_shape}')\n",
    "last_output = last_layer.output\n",
    "\n",
    "\n",
    "def add_Dense_layers(model, last_output, num_nodes, class_num, dropout):\n",
    "    #TODO\n",
    "    print('Building Dense layers...')\n",
    "    # Flatten the output layer to 1 dimension\n",
    "    x = layers.Flatten()(last_output)\n",
    "    # add a fully connected layer\n",
    "    x = layers.Dense(num_nodes, activation='relu')(x)\n",
    "    # add the dropout rate of 0.2\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    # add a final layer with softmax for classification\n",
    "    x = layers.Dense(class_num, activation='softmax')(x)\n",
    "\n",
    "    # append the created dense network to the pre_trained_model\n",
    "    dense_model = Model(model.input, x)\n",
    "\n",
    "\n",
    "    return dense_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code to construct the model can be written into the src.models.vgg19.py module to be used for training the models. The dense network method can be moved into the src.models.model_utils.py module to be used when creating each of the model architectures. This method will be called within each of the model modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO import vgg19 module and compile a model showing the summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "935f013ec3274d983f6cf9c6c8d3a038a9827a62579d2563240b276044aef7b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
