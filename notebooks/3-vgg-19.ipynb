{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. VGG-19\n",
    "\n",
    "#### Garrett McCue\n",
    "\n",
    "The first model architecture we will explore for classifying the images is the [VGG19](https://arxiv.org/abs/1409.1556) architecture. The model architecture and pretrained weights from the ImageNet dataset can easily be downloaded and compiled from [Tensorflow and Keras](https://www.tensorflow.org/api_docs/python/tf/keras/applications/vgg19) for transfer learning applications.\n",
    "\n",
    "The process of transfer learning for ConvNets includes:\n",
    "\n",
    "1. Getting only the convolutional layers and associated pretrained weights of the model.\n",
    "2. Freeze the weights of the pretrained convolutional layers\n",
    "3. Attach Dense connected layers to the top\n",
    "4. Train Dense top layers on the desired task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/garrettmccue/projects/cnn-alzheimers'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# set correct local working directory and useful paths\n",
    "ROOT = '/Users/garrettmccue/projects/cnn-alzheimers'\n",
    "data_path = f'{ROOT}/data'\n",
    "weights_path = f'{ROOT}/models/raw'\n",
    "\n",
    "os.chdir(ROOT)\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the pre-trained weights. No top means it excludes the fully connected layer it uses for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-07-17 23:16:18--  https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.190.80, 142.250.190.144, 172.217.4.208, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.190.80|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 80134624 (76M) [application/octet-stream]\n",
      "Saving to: ‘/Users/garrettmccue/projects/cnn-alzheimers/models/raw/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
      "\n",
      "/Users/garrettmccue 100%[===================>]  76.42M  15.9MB/s    in 4.6s    \n",
      "\n",
      "2022-07-17 23:16:23 (16.7 MB/s) - ‘/Users/garrettmccue/projects/cnn-alzheimers/models/raw/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [80134624/80134624]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
    "    -O /Users/garrettmccue/projects/cnn-alzheimers/models/raw/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-17 23:19:55.295100: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 256, 256, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 256, 256, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 128, 128, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 128, 128, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 128, 128, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 64, 64, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 64, 64, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 32, 32, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 16, 16, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 0\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# set the downloaded weights file to a variable\n",
    "local_weights_path = f'{weights_path}/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "# Initialize base model from tensorflow.keras\n",
    "# Set the input shape and remove dense layers (top), to match our weights file\n",
    "# our image shapes are (256x256)\n",
    "pre_trained_model = VGG19(input_shape = (256, 256, 3),\n",
    "                                include_top= False,\n",
    "                                weights = None)\n",
    "\n",
    "# load pretrained weights\n",
    "pre_trained_model.load_weights(local_weights_path)\n",
    "\n",
    "# freeze weights of each layer\n",
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "pre_trained_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the head has been removed and this network isnt as deep as the inception-v3 model we will take the output from the last layer and feed it into an attached dense network. Since we are going to be adding dense networks to more models we can create a utilities function to handle this and use it to add the dense layers to the vgg19 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_Dense_network(model, layer_size, num_classes, dropout):\n",
    "    #TODO\n",
    "    return model\n",
    "\n",
    "#TODO: add module to model.utils.py and implement function on model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code to construct the model can be complied in a function and written into the src.models.vgg19.py module to be used for training the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import vgg19 module and compile a model showing the summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "935f013ec3274d983f6cf9c6c8d3a038a9827a62579d2563240b276044aef7b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
