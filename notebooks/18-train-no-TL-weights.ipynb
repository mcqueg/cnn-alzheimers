{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18. Training Models w/o TL weights\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mcqueg/cnn-alzheimers/blob/main/notebooks/18-train-no-TL-weights.ipynb)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mount drive for saving model checkpoints\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "# load github repo and installing requirements to train the model\n",
    "!git clone https://github.com/mcqueg/cnn-alzheimers.git\n",
    "!git config --global user.name \"mcqueg\"\n",
    "!git config --global user.email \"garrettmccue@gmail.com\"\n",
    "%cd cnn-alzheimers/\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "#import project scripts\n",
    "from src.models.train_val import train_val\n",
    "\n",
    "# SET NOTEBOOK PARAMS\n",
    "\n",
    "# workspaces\n",
    "COLAB = '/content/cnn-alzheimers/'\n",
    "GDRIVE = '/content/gdrive/Othercomputers/MacBookPro/cnn-alzheimers/'\n",
    "\n",
    "# load from colab after mounting repo\n",
    "TRAIN_DIR = f'{COLAB}data/processed/ADNI/train'\n",
    "TEST_DIR = f'{COLAB}data/processed/ADNI/test'\n",
    "LOGS_DIR = f'{COLAB}/logs'\n",
    "\n",
    "# save to GDRIVE\n",
    "SAVE_DIR = f'{GDRIVE}models/checkpoints'\n",
    "\n",
    "# training params\n",
    "LR = 0.001\n",
    "VAL_SIZE = 0.5 # splits test dir in half for  validation and testing data\n",
    "EPOCHS = 500\n",
    "BATCH = 16\n",
    "CLASS_NUM = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard Training Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs --host 0.0.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception-v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "# CREATE DIRS FOR SAVING CHECKPOINTS\n",
    "NAME = 'inception-v3-no-TL'\n",
    "now = datetime.now()\n",
    "start_time = now.strftime(\"_%d-%m-%Y_%H:%M:%S\")\n",
    "name = f'{NAME}_{start_time}'\n",
    "\n",
    "os.makedirs(os.path.join(os.path.join(SAVE_DIR,name),'ckpt'), exist_ok=True)\n",
    "save_weights_path=os.path.join(os.path.join(SAVE_DIR,name), 'ckpt/')\n",
    "print(f\"\\nsaving weights at: \\n\\t{save_weights_path}\")\n",
    "\n",
    "os.makedirs(os.path.join(os.path.join(SAVE_DIR,name), 'config'), exist_ok=True)\n",
    "config_path=os.path.join(os.path.join(SAVE_DIR,name), 'config')\n",
    "print(f\"\\nsaving model architecture at: \\n\\t{config_path}\\n\")\n",
    "\n",
    "# BUILD MODEL\n",
    "base_model_inception = InceptionV3(input_shape = (256, 256, 3),\n",
    "                                include_top= False,\n",
    "                                weights = None)\n",
    "# choose last layer from the pretrained model to feed into the dense layers\n",
    "last_layer = base_model_inception.get_layer(index=-1)\n",
    "last_output = last_layer.output\n",
    "\n",
    "# add dense layers to be trained for classification by feeding last_output in dense network\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(last_output)\n",
    "# add a fully connected layer\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "# add droput\n",
    "x = layers.Dropout(0.3)(x)\n",
    "# add a final layer with softmax for classification\n",
    "x = layers.Dense(5, activation='softmax')(x)\n",
    "# create model\n",
    "inception_model = Model(base_model_inception, x)\n",
    "# -- save model architecture\n",
    "model_config = inception_model.to_json()\n",
    "with open(os.path.join(config_path, f'{name}.json'), 'w') as json_file:\n",
    "    json_file.write(model_config)\n",
    "\n",
    "#COMPILE MODEL\n",
    "inception_model.compile(optimizer = Adam(learning_rate=LR),\n",
    "                  loss = 'categorical_crossentropy',\n",
    "                  metrics = ['accuracy'])\n",
    "\n",
    "#TRAIN MODEL WITH EARLY STOPPING\n",
    "history_inception = train_val(model=inception_model,\n",
    "                    name=name,\n",
    "                    weights_path=save_weights_path,\n",
    "                    train_dir=TRAIN_DIR,\n",
    "                    test_dir =TEST_DIR,\n",
    "                    logs_dir=LOGS_DIR,\n",
    "                    save_dir=SAVE_DIR,\n",
    "                    val_size=VAL_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    lr=LR,\n",
    "                    batch_size=BATCH,\n",
    "                    evaluate=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "\n",
    "# CREATE DIRS FOR SAVING CHECKPOINTS\n",
    "NAME = 'vgg19-no-TL'\n",
    "now = datetime.now()\n",
    "start_time = now.strftime(\"_%d-%m-%Y_%H:%M:%S\")\n",
    "name = f'{NAME}_{start_time}'\n",
    "\n",
    "os.makedirs(os.path.join(os.path.join(SAVE_DIR,name),'ckpt'), exist_ok=True)\n",
    "save_weights_path=os.path.join(os.path.join(SAVE_DIR,name), 'ckpt/')\n",
    "print(f\"\\nsaving weights at: \\n\\t{save_weights_path}\")\n",
    "\n",
    "os.makedirs(os.path.join(os.path.join(SAVE_DIR,name), 'config'), exist_ok=True)\n",
    "config_path=os.path.join(os.path.join(SAVE_DIR,name), 'config')\n",
    "print(f\"\\nsaving model architecture at: \\n\\t{config_path}\\n\")\n",
    "\n",
    "# BUILD MODEL\n",
    "base_model_vgg = VGG19(input_shape = (256, 256, 3),\n",
    "                                include_top= False,\n",
    "                                weights = None)\n",
    "# choose last layer from the pretrained model to feed into the dense layers\n",
    "last_layer = base_model_vgg.get_layer(index=-1)\n",
    "last_output = last_layer.output\n",
    "\n",
    "# add dense layers to be trained for classification by feeding last_output in dense network\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(last_output)\n",
    "# add a fully connected layer\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "# add droput\n",
    "x = layers.Dropout(0.3)(x)\n",
    "# add a final layer with softmax for classification\n",
    "x = layers.Dense(5, activation='softmax')(x)\n",
    "# create model\n",
    "vgg_model = Model(base_model_vgg, x)\n",
    "# -- save model architecture\n",
    "model_config = vgg_model.to_json()\n",
    "with open(os.path.join(config_path, f'{name}.json'), 'w') as json_file:\n",
    "    json_file.write(model_config)\n",
    "\n",
    "#COMPILE MODEL\n",
    "vgg_model.compile(optimizer = Adam(learning_rate=LR),\n",
    "                  loss = 'categorical_crossentropy',\n",
    "                  metrics = ['accuracy'])\n",
    "\n",
    "#TRAIN MODEL WITH EARLY STOPPING\n",
    "history_vgg = train_val(model=vgg_model,\n",
    "                    name=name,\n",
    "                    weights_path=save_weights_path,\n",
    "                    train_dir=TRAIN_DIR,\n",
    "                    test_dir =TEST_DIR,\n",
    "                    logs_dir=LOGS_DIR,\n",
    "                    save_dir=SAVE_DIR,\n",
    "                    val_size=VAL_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    lr=LR,\n",
    "                    batch_size=BATCH,\n",
    "                    evaluate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "# CREATE DIRS FOR SAVING CHECKPOINTS\n",
    "NAME = 'resnet50-no-TL'\n",
    "now = datetime.now()\n",
    "start_time = now.strftime(\"_%d-%m-%Y_%H:%M:%S\")\n",
    "name = f'{NAME}_{start_time}'\n",
    "\n",
    "os.makedirs(os.path.join(os.path.join(SAVE_DIR,name),'ckpt'), exist_ok=True)\n",
    "save_weights_path=os.path.join(os.path.join(SAVE_DIR,name), 'ckpt/')\n",
    "print(f\"\\nsaving weights at: \\n\\t{save_weights_path}\")\n",
    "\n",
    "os.makedirs(os.path.join(os.path.join(SAVE_DIR,name), 'config'), exist_ok=True)\n",
    "config_path=os.path.join(os.path.join(SAVE_DIR,name), 'config')\n",
    "print(f\"\\nsaving model architecture at: \\n\\t{config_path}\\n\")\n",
    "\n",
    "# BUILD MODEL\n",
    "base_model_resnet = ResNet50(input_shape = (256, 256, 3),\n",
    "                                include_top= False,\n",
    "                                weights = None)\n",
    "# choose last layer from the pretrained model to feed into the dense layers\n",
    "last_layer = base_model_resnet.get_layer(index=-1)\n",
    "last_output = last_layer.output\n",
    "\n",
    "# add dense layers to be trained for classification by feeding last_output in dense network\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(last_output)\n",
    "# add a fully connected layer\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "# add droput\n",
    "x = layers.Dropout(0.3)(x)\n",
    "# add a final layer with softmax for classification\n",
    "x = layers.Dense(5, activation='softmax')(x)\n",
    "# create model\n",
    "resnet_model = Model(base_model_resnet, x)\n",
    "# -- save model architecture\n",
    "model_config = resnet_model.to_json()\n",
    "with open(os.path.join(config_path, f'{name}.json'), 'w') as json_file:\n",
    "    json_file.write(model_config)\n",
    "\n",
    "#COMPILE MODEL\n",
    "resnet_model.compile(optimizer = Adam(learning_rate=LR),\n",
    "                  loss = 'categorical_crossentropy',\n",
    "                  metrics = ['accuracy'])\n",
    "\n",
    "#TRAIN MODEL WITH EARLY STOPPING\n",
    "history_resnet = train_val(model=resnet_model,\n",
    "                    name=name,\n",
    "                    weights_path=save_weights_path,\n",
    "                    train_dir=TRAIN_DIR,\n",
    "                    test_dir =TEST_DIR,\n",
    "                    logs_dir=LOGS_DIR,\n",
    "                    save_dir=SAVE_DIR,\n",
    "                    val_size=VAL_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    lr=LR,\n",
    "                    batch_size=BATCH,\n",
    "                    evaluate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.xception import Xception\n",
    "\n",
    "# CREATE DIRS FOR SAVING CHECKPOINTS\n",
    "NAME = 'xception-no-TL'\n",
    "now = datetime.now()\n",
    "start_time = now.strftime(\"_%d-%m-%Y_%H:%M:%S\")\n",
    "name = f'{NAME}_{start_time}'\n",
    "\n",
    "os.makedirs(os.path.join(os.path.join(SAVE_DIR,name),'ckpt'), exist_ok=True)\n",
    "save_weights_path=os.path.join(os.path.join(SAVE_DIR,name), 'ckpt/')\n",
    "print(f\"\\nsaving weights at: \\n\\t{save_weights_path}\")\n",
    "\n",
    "os.makedirs(os.path.join(os.path.join(SAVE_DIR,name), 'config'), exist_ok=True)\n",
    "config_path=os.path.join(os.path.join(SAVE_DIR,name), 'config')\n",
    "print(f\"\\nsaving model architecture at: \\n\\t{config_path}\\n\")\n",
    "\n",
    "# BUILD MODEL\n",
    "base_model_xception = Xception(input_shape = (256, 256, 3),\n",
    "                                include_top= False,\n",
    "                                weights = None)\n",
    "# choose last layer from the pretrained model to feed into the dense layers\n",
    "last_layer = base_model_xception.get_layer(index=-1)\n",
    "last_output = last_layer.output\n",
    "\n",
    "# add dense layers to be trained for classification by feeding last_output in dense network\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(last_output)\n",
    "# add a fully connected layer\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "# add droput\n",
    "x = layers.Dropout(0.3)(x)\n",
    "# add a final layer with softmax for classification\n",
    "x = layers.Dense(5, activation='softmax')(x)\n",
    "# create model\n",
    "xception_model = Model(base_model_xception, x)\n",
    "# -- save model architecture\n",
    "model_config = xception_model.to_json()\n",
    "with open(os.path.join(config_path, f'{name}.json'), 'w') as json_file:\n",
    "    json_file.write(model_config)\n",
    "\n",
    "#COMPILE MODEL\n",
    "xception_model.compile(optimizer = Adam(learning_rate=LR),\n",
    "                  loss = 'categorical_crossentropy',\n",
    "                  metrics = ['accuracy'])\n",
    "\n",
    "#TRAIN MODEL WITH EARLY STOPPING\n",
    "history_xception = train_val(model=xception_model,\n",
    "                    name=name,\n",
    "                    weights_path=save_weights_path,\n",
    "                    train_dir=TRAIN_DIR,\n",
    "                    test_dir =TEST_DIR,\n",
    "                    logs_dir=LOGS_DIR,\n",
    "                    save_dir=SAVE_DIR,\n",
    "                    val_size=VAL_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    lr=LR,\n",
    "                    batch_size=BATCH,\n",
    "                    evaluate=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "935f013ec3274d983f6cf9c6c8d3a038a9827a62579d2563240b276044aef7b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
